{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9963f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143d9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class SentenceNegator:\n",
    "  IRREGULAR_ES_VERB_ENDINGS = [\"ss\", \"x\", \"ch\", \"sh\", \"o\"]\n",
    "\n",
    "  def negate(self, sentence):\n",
    "    # is\n",
    "    if sentence.find(\"isn't\") > -1:\n",
    "      return sentence.replace(\"isn't\", \"is\")\n",
    "\n",
    "    if sentence.find(\"isn\\\\'t\") > -1:\n",
    "      return sentence.replace(\"isn\\\\'t\", \"is\")\n",
    "\n",
    "    if sentence.find(\"is not \") > -1:\n",
    "      return sentence.replace(\"is not \", \"is \")\n",
    "\n",
    "    if sentence.find(\"is \") > -1:\n",
    "      return sentence.replace(\"is \", \"is not \")\n",
    "\n",
    "    # has\n",
    "    if sentence.find(\"does not have\") > -1:\n",
    "      return sentence.replace(\"does not have\", \"has\")\n",
    "\n",
    "    if sentence.find(\"doesn't have\") > -1:\n",
    "      return sentence.replace(\"doesn't have\", \"has\")\n",
    "\n",
    "    if sentence.find(\"doesn\\\\'t have\") > -1:\n",
    "      return sentence.replace(\"doesn\\\\'t have\", \"has\")\n",
    "\n",
    "    if sentence.find(\"has \") > -1:\n",
    "      return sentence.replace(\"has \", \"does not have \")\n",
    "\n",
    "    # should\n",
    "    if sentence.find(\"shouldn't\") > -1:\n",
    "      return sentence.replace(\"shouldn't\", \"should\")\n",
    "\n",
    "    if sentence.find(\"shouldn\\\\'t\") > -1:\n",
    "      return sentence.replace(\"shouldn\\\\'t\", \"should\")\n",
    "\n",
    "    if sentence.find(\"should not\") > -1:\n",
    "      return sentence.replace(\"should not\", \"should\")\n",
    "\n",
    "    if sentence.find(\"should\") > -1:\n",
    "      return sentence.replace(\"should\", \"should not\")\n",
    "\n",
    "    # must\n",
    "    if sentence.find(\"mustn't\") > -1:\n",
    "      return sentence.replace(\"mustn't\", \"must\")\n",
    "\n",
    "    if sentence.find(\"mustn\\\\'t\") > -1:\n",
    "      return sentence.replace(\"mustn\\\\'t\", \"must\")\n",
    "\n",
    "    if sentence.find(\"must not\") > -1:\n",
    "      return sentence.replace(\"must not\", \"must\")\n",
    "\n",
    "    if sentence.find(\"must \") > -1:\n",
    "      return sentence.replace(\"must \", \"must not \")\n",
    "\n",
    "    # can\n",
    "    if sentence.find(\"can't\") > -1:\n",
    "      return sentence.replace(\"can't\", \"can\")\n",
    "\n",
    "    if sentence.find(\"can\\\\'t\") > -1:\n",
    "      return sentence.replace(\"can\\\\'t\", \"can\")\n",
    "\n",
    "    if sentence.find(\"cannot\") > -1:\n",
    "      return sentence.replace(\"cannot\", \"can\")\n",
    "\n",
    "    if sentence.find(\"can \") > -1:\n",
    "      return sentence.replace(\"can \", \"cannot \")\n",
    "    # was\n",
    "    if sentence.find(\" was \") > -1:\n",
    "      return sentence.replace(\" was \", \" was not \")\n",
    "    if sentence.find(\"was not \") > -1:\n",
    "      return sentence.replace(\"was not \", \"was \")\n",
    "    if sentence.find(\"wasn't\") > -1:\n",
    "      return sentence.replace(\"wasn't\", \"was\")\n",
    "    # doesn't work -> works\n",
    "    doesnt_regex = r'(doesn\\'t|doesn\\\\\\'t|does not) (?P<verb>\\w+)'\n",
    "\n",
    "    if re.search(doesnt_regex, sentence):\n",
    "      def replace_doesnt(matchobj):\n",
    "        verb = matchobj.group(2)\n",
    "\n",
    "        if verb.endswith(\"y\") and self.__is_consonant(verb[-2]):\n",
    "          return \"{0}ies\".format(verb[0:-1])\n",
    "\n",
    "        for ending in self.IRREGULAR_ES_VERB_ENDINGS:\n",
    "          if verb.endswith(ending):\n",
    "            return \"{0}es\".format(verb)\n",
    "\n",
    "        return \"{0}s\".format(verb)\n",
    "\n",
    "      return re.sub(doesnt_regex, replace_doesnt, sentence, 1)\n",
    "\n",
    "    verb_regex = r'(It |it |)(?P<verb>\\w+)s( |$)'\n",
    "\n",
    "    # works -> does not work\n",
    "    def replace_verb(matchobj):\n",
    "      subject = matchobj.group(1)\n",
    "      verb = matchobj.group(2)\n",
    "      whitespace = matchobj.group(3)\n",
    "\n",
    "      # flies -> fly, but not die -> dy\n",
    "      if verb.endswith(\"ie\") and len(verb) > 3:\n",
    "        verb = \"{0}y\".format(verb[0:-2])\n",
    "\n",
    "      # stresses -> stress\n",
    "      for ending in self.IRREGULAR_ES_VERB_ENDINGS:\n",
    "        if verb.endswith(\"{0}e\".format(ending)):\n",
    "          verb = verb[0:-1]\n",
    "\n",
    "      return \"{0}does not {1}{2}\".format(subject, verb, whitespace)\n",
    "\n",
    "    if re.search(verb_regex, sentence):\n",
    "      return re.sub(verb_regex, replace_verb, sentence, 1)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "  def __is_consonant(self, letter):\n",
    "    return letter not in ['a', 'e', 'i', 'o', 'u', 'y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53dd889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 s, sys: 596 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "root = '.'\n",
    "\n",
    "train_data = list(\n",
    "    map(json.loads, open(f\"{root}/cosmos/train_data.json\").readlines())\n",
    ")\n",
    "test_data = list(\n",
    "    map(json.loads, open(f\"{root}/cosmos/test_data.json\").readlines())\n",
    ")\n",
    "val_data = list(map(json.loads, open(f\"{root}/cosmos/val_data.json\").readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f25b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 18372/80877 [00:00<00:00, 91957.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pro-democracy activist covered in blue paint uses a megaphone during an anti-government protest, in GPE, GPE DATE.\n",
      "A pro-democracy activist covered in blue paint uses a megaphone during an anti-government protest, in GPE, GPE DATE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80877/80877 [00:00<00:00, 91667.89it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "train_data_sample = np.random.choice(train_data, size=int(len(train_data)*50/100))\n",
    "# Not OOC cases\n",
    "sn = SentenceNegator()\n",
    "l = []\n",
    "nice=0\n",
    "ne=0\n",
    "bad=0\n",
    "for data in tqdm(train_data_sample):\n",
    "    if len(data['articles']) > 1:\n",
    "        # Pick 2 random caption\n",
    "        caption_1_idx, caption_2_idx = random.sample(range(0,len(data['articles'])),2)\n",
    "        cap1 = data['articles'][caption_1_idx]['caption_modified']\n",
    "        cap2 = data['articles'][caption_2_idx]['caption_modified']\n",
    "        if data['img_local_path'] == 'train/109750.jpg':\n",
    "            print(cap1)\n",
    "            print(cap2)\n",
    "        if cap1 != cap2:\n",
    "            l.append([data['img_local_path'],[cap1],[cap2],[False]])\n",
    "            nice += 1\n",
    "        else:\n",
    "            cap2 = sn.negate(cap2)\n",
    "            if cap1 != cap2:\n",
    "                l.append([data['img_local_path'],[cap1],[cap2],[True]])\n",
    "                ne += 1\n",
    "\n",
    "    if len(data['articles']) == 1 and np.random.rand() > 0.5:\n",
    "        if np.random.rand()>0.5:\n",
    "            data_random1 = train_data[np.random.randint(len(train_data))]\n",
    "            while data['img_local_path'] == data_random1['img_local_path']:\n",
    "                data_random1 = train_data[np.random.randint(len(train_data))]\n",
    "            cap1 = data_random1['articles'][np.random.randint(len(data_random1['articles']))]['caption_modified']\n",
    "            data_random2 = train_data[np.random.randint(len(train_data))]\n",
    "            while data['img_local_path'] == data_random2['img_local_path']:\n",
    "                data_random2 = train_data[np.random.randint(len(train_data))]\n",
    "            cap2 = data_random2['articles'][np.random.randint(len(data_random2['articles']))]['caption_modified']\n",
    "        else:\n",
    "             # Pick 1st correct caption\n",
    "            if np.random.rand()>0.5:\n",
    "                cap1 = data['articles'][np.random.randint(len(data['articles']))]['caption_modified']\n",
    "                # Pick a random article then pick its first caption\n",
    "                data_random = train_data[np.random.randint(len(train_data))]\n",
    "                while data['img_local_path'] == data_random['img_local_path']:\n",
    "                    data_random = train_data[np.random.randint(len(train_data))]\n",
    "                cap2 = data_random['articles'][np.random.randint(len(data_random['articles']))]['caption_modified']\n",
    "            else:\n",
    "                cap2 = data['articles'][np.random.randint(len(data['articles']))]['caption_modified']\n",
    "                # Pick a random article then pick its first caption\n",
    "                data_random = train_data[np.random.randint(len(train_data))]\n",
    "                if data['img_local_path'] == data_random['img_local_path']:\n",
    "                    continue\n",
    "                cap1 = data_random['articles'][np.random.randint(len(data_random['articles']))]['caption_modified']\n",
    "        l.append([data['img_local_path'],[cap1],[cap2],[True]])\n",
    "        bad+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b491360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(\n",
    "    l, columns=[\"image\", \"caption_1\", \"caption_2\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e25773d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    30974\n",
       "True     30784\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['label'].apply(lambda x:x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ccdd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "   try:\n",
    "      with open(path, \"rb\") as fp:\n",
    "        return fp.read()\n",
    "   except:\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20de3ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/vilt/lib/python3.8/site-packages/tqdm/std.py:702: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 61735/61735 [00:10<00:00, 5748.73it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "dataframe['image'] = dataframe['image'].progress_apply(lambda x: load_image(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b1b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe[dataframe.image.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10037d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[Voters mark their ballots during early voting...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[PERSON. But How Many Children He Has In Total...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[GPE's premature baby was delivered by emergen...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[The DATE on GPE  Photo Gallery of the DATE on...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[A Rohingya refugee man holds his child up as ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                              image  \\\n",
       "0         0  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "1         1  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "2         2  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "3         3  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "4         4  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "\n",
       "                                             caption  split  \n",
       "0  [Voters mark their ballots during early voting...  train  \n",
       "1  [PERSON. But How Many Children He Has In Total...  train  \n",
       "2  [GPE's premature baby was delivered by emergen...  train  \n",
       "3  [The DATE on GPE  Photo Gallery of the DATE on...  train  \n",
       "4  [A Rohingya refugee man holds his child up as ...  train  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa = dataframe.rename(columns={'caption_1':'caption'}).drop(columns=['caption_2','label'])\n",
    "fa['split'] = 'train'\n",
    "fa = fa.rename_axis('image_id').reset_index()\n",
    "fa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dd8b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(fa)\n",
    "split = 'train'\n",
    "with pa.OSFile(f\"fa/f30k_caption_karpathy_test.arrow\", \"wb\") as sink:\n",
    "    with pa.RecordBatchFileWriter(sink, table.schema) as writer:\n",
    "        writer.write_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17699db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vilt.datasets import F30KCaptionKarpathyDataset\n",
    "import torch\n",
    "from transformers import (\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForWholeWordMask,\n",
    "    BertTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da5f38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_tokenizer(from_pretrained):\n",
    "    if torch.distributed.is_initialized():\n",
    "        if torch.distributed.get_rank() == 0:\n",
    "            BertTokenizer.from_pretrained(\n",
    "                from_pretrained, do_lower_case=\"uncased\" in from_pretrained\n",
    "            )\n",
    "        torch.distributed.barrier()\n",
    "    return BertTokenizer.from_pretrained(\n",
    "        from_pretrained, do_lower_case=\"uncased\" in from_pretrained\n",
    "    )\n",
    "tokenizer = get_pretrained_tokenizer(\"bert-base-uncased\")\n",
    "n = F30KCaptionKarpathyDataset(data_dir='fa', split='train',transform_keys=[\"pixelbert_randaug\"],image_size=384)\n",
    "n.tokenizer = tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb7f1602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': [tensor([[[ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       "  \n",
       "          [[ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       "  \n",
       "          [[ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           [ 0.0039,  0.0039,  0.0039,  ...,  0.0039,  0.0039,  0.0039],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]])],\n",
       " 'img_index': 10,\n",
       " 'cap_index': 0,\n",
       " 'raw_index': 10,\n",
       " 'replica': False,\n",
       " 'text': ('PERSON plans to promote PERSON in GPE and GPE (photo)',\n",
       "  {'input_ids': [101, 2711, 3488, 2000, 5326, 2711, 1999, 14246, 2063, 1998, 14246, 2063, 1006, 6302, 1007, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dddccd0",
   "metadata": {},
   "source": [
    "# PyArrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47eda01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f266cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "with pa.OSFile(f\"dataset_neg/cosmos_{split}.arrow\", \"wb\") as sink:\n",
    "    with pa.RecordBatchFileWriter(sink, table.schema) as writer:\n",
    "        writer.write_table(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4ed3e",
   "metadata": {},
   "source": [
    "# Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc8ac523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20503/20503 [00:00<00:00, 89303.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "val_data_sample = np.random.choice(val_data, size=int(len(val_data)*50/100))\n",
    "# train_data_sample=train_data[:1]\n",
    "# Not OOC cases\n",
    "nice = 0\n",
    "ne = 0\n",
    "bad = 0\n",
    "l = []\n",
    "for data in tqdm(val_data_sample):\n",
    "    if len(data['articles']) > 1:\n",
    "        # Pick 2 random caption\n",
    "        caption_1_idx, caption_2_idx = random.sample(range(0,len(data['articles'])),2)\n",
    "        cap1 = data['articles'][caption_1_idx]['caption_modified']\n",
    "        cap2 = data['articles'][caption_2_idx]['caption_modified']\n",
    "        if data['img_local_path'] == 'train/109750.jpg':\n",
    "            print(cap1)\n",
    "            print(cap2)\n",
    "        if cap1 != cap2:\n",
    "            l.append([data['img_local_path'],[cap1],[cap2],[False]])\n",
    "            nice += 1\n",
    "        else:\n",
    "            cap2 = sn.negate(cap2)\n",
    "            if cap1 != cap2:\n",
    "                l.append([data['img_local_path'],[cap1],[cap2],[True]])\n",
    "                ne += 1\n",
    "\n",
    "    if len(data['articles']) == 1 and np.random.rand() > 0.5:\n",
    "        if np.random.rand()>0.5:\n",
    "            data_random1 = train_data[np.random.randint(len(train_data))]\n",
    "            while data['img_local_path'] == data_random1['img_local_path']:\n",
    "                data_random1 = train_data[np.random.randint(len(train_data))]\n",
    "            cap1 = data_random1['articles'][np.random.randint(len(data_random1['articles']))]['caption_modified']\n",
    "            data_random2 = train_data[np.random.randint(len(train_data))]\n",
    "            while data['img_local_path'] == data_random2['img_local_path']:\n",
    "                data_random2 = train_data[np.random.randint(len(train_data))]\n",
    "            cap2 = data_random2['articles'][np.random.randint(len(data_random2['articles']))]['caption_modified']\n",
    "        else:\n",
    "             # Pick 1st correct caption\n",
    "            if np.random.rand()>0.5:\n",
    "                cap1 = data['articles'][np.random.randint(len(data['articles']))]['caption_modified']\n",
    "                # Pick a random article then pick its first caption\n",
    "                data_random = train_data[np.random.randint(len(train_data))]\n",
    "                while data['img_local_path'] == data_random['img_local_path']:\n",
    "                    data_random = train_data[np.random.randint(len(train_data))]\n",
    "                cap2 = data_random['articles'][np.random.randint(len(data_random['articles']))]['caption_modified']\n",
    "            else:\n",
    "                cap2 = data['articles'][np.random.randint(len(data['articles']))]['caption_modified']\n",
    "                # Pick a random article then pick its first caption\n",
    "                data_random = train_data[np.random.randint(len(train_data))]\n",
    "                if data['img_local_path'] == data_random['img_local_path']:\n",
    "                    continue\n",
    "                cap1 = data_random['articles'][np.random.randint(len(data_random['articles']))]['caption_modified']\n",
    "        l.append([data['img_local_path'],[cap1],[cap2],[True]])\n",
    "        bad+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3796897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7738, 4076, 3774)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nice,ne,bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fd1aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(\n",
    "    l, columns=[\"image\", \"caption_1\", \"caption_2\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "276d797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/vilt/lib/python3.8/site-packages/tqdm/std.py:702: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 15588/15588 [00:01<00:00, 14784.73it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "dataframe['image'] = dataframe['image'].progress_apply(lambda x: load_image(x))\n",
    "dataframe = dataframe[dataframe.image.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a841c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(dataframe)\n",
    "split = 'val'\n",
    "with pa.OSFile(f\"dataset_neg/cosmos_{split}.arrow\", \"wb\") as sink:\n",
    "    with pa.RecordBatchFileWriter(sink, table.schema) as writer:\n",
    "        writer.write_table(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e629f",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "614eb437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2c7e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_caption_replace_entities(caption_text):\n",
    "    \"\"\"\n",
    "        Utility function to replace named entities in the caption with their corresponding hypernyms\n",
    "        Args:\n",
    "            caption_text (str): Original caption with named entities\n",
    "        Returns:\n",
    "            caption_modified (str): Modified caption after replacing named entities\n",
    "    \"\"\"\n",
    "    doc = nlp(caption_text)\n",
    "    caption_modified = caption_text\n",
    "    caption_entity_list = []\n",
    "    for ent in doc.ents:\n",
    "        caption_entity_list.append((ent.text, ent.label_))\n",
    "        caption_modified = caption_modified.replace(ent.text, ent.label_, 1)\n",
    "    return caption_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cbb1ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [00:18<00:00, 91.35it/s]\n"
     ]
    }
   ],
   "source": [
    "l_test  = []\n",
    "for data in tqdm(test_data):\n",
    "    cap1 = modify_caption_replace_entities(data['caption1'])\n",
    "    cap2 = modify_caption_replace_entities(data['caption2'])\n",
    "    l_test.append([data['img_local_path'],[cap1],[cap2],[data['context_label']==True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2b8b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test = pd.DataFrame(\n",
    "    l_test, columns=[\"image\", \"caption_1\", \"caption_2\", \"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "85fa816d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/0.jpg</td>\n",
       "      <td>[PERSON at his announcement in GPE, GPE, on DA...</td>\n",
       "      <td>[PERSON at his announcement in GPE, GPE, on DA...</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/1.jpg</td>\n",
       "      <td>[Supporters of GPE's ruling ORG party come out...</td>\n",
       "      <td>[A person sits on a truck as supporters of the...</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/2.jpg</td>\n",
       "      <td>[CARDINAL dead people turned up on the state’s...</td>\n",
       "      <td>[These social media posts did not link to a re...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/3.jpg</td>\n",
       "      <td>[Actor, musician, director and devoted followe...</td>\n",
       "      <td>[A shocking report about the former child acto...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/4.jpg</td>\n",
       "      <td>[Men from the LOC tribe perform a traditional ...</td>\n",
       "      <td>[And on DATE in GPE's Narok county, young PERS...</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>test/1695.jpg</td>\n",
       "      <td>[President PERSON trademarked the name 'WORK_O...</td>\n",
       "      <td>[There was no truth that PERSON family MONEY w...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>test/1696.jpg</td>\n",
       "      <td>[A photograph shows a soldier carrying a donke...</td>\n",
       "      <td>[Coronavirus meme featuring “EVENT donkey” is ...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>test/1697.jpg</td>\n",
       "      <td>[Homeless people living on streets in GPE]</td>\n",
       "      <td>[ORG in GPE]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>test/1698.jpg</td>\n",
       "      <td>[The castle's esplanade was a perfect spot for...</td>\n",
       "      <td>[Picture shows an ORG skier]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>test/1699.jpg</td>\n",
       "      <td>[We are confident that our reporting will stan...</td>\n",
       "      <td>[ORG Editor-in-Chief PERSON poses for a pictur...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image                                          caption_1  \\\n",
       "0        test/0.jpg  [PERSON at his announcement in GPE, GPE, on DA...   \n",
       "1        test/1.jpg  [Supporters of GPE's ruling ORG party come out...   \n",
       "2        test/2.jpg  [CARDINAL dead people turned up on the state’s...   \n",
       "3        test/3.jpg  [Actor, musician, director and devoted followe...   \n",
       "4        test/4.jpg  [Men from the LOC tribe perform a traditional ...   \n",
       "...             ...                                                ...   \n",
       "1695  test/1695.jpg  [President PERSON trademarked the name 'WORK_O...   \n",
       "1696  test/1696.jpg  [A photograph shows a soldier carrying a donke...   \n",
       "1697  test/1697.jpg         [Homeless people living on streets in GPE]   \n",
       "1698  test/1698.jpg  [The castle's esplanade was a perfect spot for...   \n",
       "1699  test/1699.jpg  [We are confident that our reporting will stan...   \n",
       "\n",
       "                                              caption_2    label  \n",
       "0     [PERSON at his announcement in GPE, GPE, on DA...  [False]  \n",
       "1     [A person sits on a truck as supporters of the...  [False]  \n",
       "2     [These social media posts did not link to a re...   [True]  \n",
       "3     [A shocking report about the former child acto...   [True]  \n",
       "4     [And on DATE in GPE's Narok county, young PERS...  [False]  \n",
       "...                                                 ...      ...  \n",
       "1695  [There was no truth that PERSON family MONEY w...   [True]  \n",
       "1696  [Coronavirus meme featuring “EVENT donkey” is ...   [True]  \n",
       "1697                                       [ORG in GPE]  [False]  \n",
       "1698                       [Picture shows an ORG skier]  [False]  \n",
       "1699  [ORG Editor-in-Chief PERSON poses for a pictur...   [True]  \n",
       "\n",
       "[1700 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ba1d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/vilt/lib/python3.8/site-packages/tqdm/std.py:702: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 1700/1700 [00:00<00:00, 8804.80it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "dataframe_test['image'] = dataframe_test['image'].progress_apply(lambda x: load_image(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a5dc6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[PERSON at his announcement in GPE, GPE, on DA...</td>\n",
       "      <td>[PERSON at his announcement in GPE, GPE, on DA...</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[Supporters of GPE's ruling ORG party come out...</td>\n",
       "      <td>[A person sits on a truck as supporters of the...</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[CARDINAL dead people turned up on the state’s...</td>\n",
       "      <td>[These social media posts did not link to a re...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[Actor, musician, director and devoted followe...</td>\n",
       "      <td>[A shocking report about the former child acto...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[Men from the LOC tribe perform a traditional ...</td>\n",
       "      <td>[And on DATE in GPE's Narok county, young PERS...</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[President PERSON trademarked the name 'WORK_O...</td>\n",
       "      <td>[There was no truth that PERSON family MONEY w...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[A photograph shows a soldier carrying a donke...</td>\n",
       "      <td>[Coronavirus meme featuring “EVENT donkey” is ...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[Homeless people living on streets in GPE]</td>\n",
       "      <td>[ORG in GPE]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[The castle's esplanade was a perfect spot for...</td>\n",
       "      <td>[Picture shows an ORG skier]</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "      <td>[We are confident that our reporting will stan...</td>\n",
       "      <td>[ORG Editor-in-Chief PERSON poses for a pictur...</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  \\\n",
       "0     b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "1     b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "2     b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "3     b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "4     b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "...                                                 ...   \n",
       "1695  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "1696  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "1697  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "1698  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "1699  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...   \n",
       "\n",
       "                                              caption_1  \\\n",
       "0     [PERSON at his announcement in GPE, GPE, on DA...   \n",
       "1     [Supporters of GPE's ruling ORG party come out...   \n",
       "2     [CARDINAL dead people turned up on the state’s...   \n",
       "3     [Actor, musician, director and devoted followe...   \n",
       "4     [Men from the LOC tribe perform a traditional ...   \n",
       "...                                                 ...   \n",
       "1695  [President PERSON trademarked the name 'WORK_O...   \n",
       "1696  [A photograph shows a soldier carrying a donke...   \n",
       "1697         [Homeless people living on streets in GPE]   \n",
       "1698  [The castle's esplanade was a perfect spot for...   \n",
       "1699  [We are confident that our reporting will stan...   \n",
       "\n",
       "                                              caption_2    label  \n",
       "0     [PERSON at his announcement in GPE, GPE, on DA...  [False]  \n",
       "1     [A person sits on a truck as supporters of the...  [False]  \n",
       "2     [These social media posts did not link to a re...   [True]  \n",
       "3     [A shocking report about the former child acto...   [True]  \n",
       "4     [And on DATE in GPE's Narok county, young PERS...  [False]  \n",
       "...                                                 ...      ...  \n",
       "1695  [There was no truth that PERSON family MONEY w...   [True]  \n",
       "1696  [Coronavirus meme featuring “EVENT donkey” is ...   [True]  \n",
       "1697                                       [ORG in GPE]  [False]  \n",
       "1698                       [Picture shows an ORG skier]  [False]  \n",
       "1699  [ORG Editor-in-Chief PERSON poses for a pictur...   [True]  \n",
       "\n",
       "[1700 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "155e1c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     850\n",
       "False    850\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test['label'].apply(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cc20ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "shuffled = dataframe_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da3641cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffled[:1000]\n",
    "val = shuffled[1000:1350]\n",
    "test = shuffled[1350:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acc568ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    178\n",
       "True     172\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'].apply(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219bfdb9",
   "metadata": {},
   "source": [
    "# PyArrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "250c78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe,split in zip([train,val,test],['train','val','test']):\n",
    "    table = pa.Table.from_pandas(dataframe)\n",
    "    # split = 'test'\n",
    "    with pa.OSFile(f\"dataset_test_only/cosmos_{split}.arrow\", \"wb\") as sink:\n",
    "        with pa.RecordBatchFileWriter(sink, table.schema) as writer:\n",
    "            writer.write_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35530120",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(dataframe_test)\n",
    "split = 'test'\n",
    "with pa.OSFile(f\"dataset_neg/cosmos_{split}.arrow\", \"wb\") as sink:\n",
    "    with pa.RecordBatchFileWriter(sink, table.schema) as writer:\n",
    "        writer.write_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_tokenizer(from_pretrained):\n",
    "    if torch.distributed.is_initialized():\n",
    "        if torch.distributed.get_rank() == 0:\n",
    "            BertTokenizer.from_pretrained(\n",
    "                from_pretrained, do_lower_case=\"uncased\" in from_pretrained\n",
    "            )\n",
    "        torch.distributed.barrier()\n",
    "    return BertTokenizer.from_pretrained(\n",
    "        from_pretrained, do_lower_case=\"uncased\" in from_pretrained\n",
    "    )\n",
    "tokenizer = get_pretrained_tokenizer(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d7af4",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed24acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vilt.datasets.base_dataset import BaseDataset\n",
    "class COSMOSDataset(BaseDataset):\n",
    "    def __init__(self, *args, split=\"\", **kwargs):\n",
    "        assert split in [\"train\", \"val\", \"test\"]\n",
    "        self.split = split\n",
    "\n",
    "        if split == \"train\":\n",
    "            names = [\"cosmos_train\"]\n",
    "        elif split == \"val\":\n",
    "            names = [\"cosmos_val\", \"cosmos_test\"]\n",
    "        elif split == \"test\":\n",
    "            names = [\"cosmos_val\", \"cosmos_test\"]\n",
    "\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            **kwargs,\n",
    "            names=names,\n",
    "            text_column_name=\"caption_1\",\n",
    "            remove_duplicate=False,\n",
    "        )\n",
    "    \n",
    "    def get_text_2(self, raw_index):\n",
    "        index, caption_index = self.index_mapper[raw_index]\n",
    "        text = self.table['caption_2'][index][0].as_py()\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_text_len,\n",
    "            return_special_tokens_mask=True,\n",
    "        )\n",
    "        return {\n",
    "            \"text\": (text, encoding),\n",
    "            \"img_index\": index,\n",
    "            \"cap_index\": caption_index,\n",
    "            \"raw_index\": raw_index,\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        result = None\n",
    "        while result is None:\n",
    "            try:\n",
    "                image_tensor = self.get_image(index, image_key=\"image\")[\"image\"]\n",
    "                text = self.get_text(index)[\"text\"]\n",
    "                text2 = self.get_text_2(index)[\"text\"]\n",
    "                result = True\n",
    "            except:\n",
    "                print(\n",
    "                    f\"error while read file idx {index} in {self.names[0]}\",\n",
    "                    file=sys.stderr,\n",
    "                )\n",
    "                z\n",
    "                index = random.randint(0, len(self.index_mapper) - 1)\n",
    "\n",
    "        return {\n",
    "            \"image\": image_tensor,\n",
    "            \"text\": text,\n",
    "            \"text2\": text2,\n",
    "            \"answers\": self.table[\"label\"][index] == True,\n",
    "            \"table_name\": self.table_names[index],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a431314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokenizer from\n",
    "import torch\n",
    "from transformers import (\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForWholeWordMask,\n",
    "    BertTokenizer,\n",
    ")\n",
    "\n",
    "def get_pretrained_tokenizer(from_pretrained):\n",
    "    if torch.distributed.is_initialized():\n",
    "        if torch.distributed.get_rank() == 0:\n",
    "            BertTokenizer.from_pretrained(\n",
    "                from_pretrained, do_lower_case=\"uncased\" in from_pretrained\n",
    "            )\n",
    "        torch.distributed.barrier()\n",
    "    return BertTokenizer.from_pretrained(\n",
    "        from_pretrained, do_lower_case=\"uncased\" in from_pretrained\n",
    "    )\n",
    "tokenizer = get_pretrained_tokenizer(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "187162f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = COSMOSDataset(data_dir='dataset', split='train', transform_keys=[\"pixelbert_randaug\"],image_size=384)\n",
    "n.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fa2abee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Mr. Zuckerberg wants to increase the utility of the social network to keep Facebook's billions of users highly engaged, people involved in the effort said.\",\n",
       " {'input_ids': [101, 2720, 1012, 16950, 9102, 4059, 4122, 2000, 3623, 1996, 9710, 1997, 1996, 2591, 2897, 2000, 2562, 9130, 1005, 1055, 25501, 1997, 5198, 3811, 5117, 1010, 2111, 2920, 1999, 1996, 3947, 2056, 1012, 102, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[1]['text2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af3a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
