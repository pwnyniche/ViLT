{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "from PIL import Image\n",
    "import pyarrow as pa\n",
    "from vilt.config import ex\n",
    "from vilt.modules import ViLTransformerSS\n",
    "\n",
    "from vilt.modules.objectives import cost_matrix_cosine, ipot\n",
    "from vilt.transforms import pixelbert_transform\n",
    "from vilt.datamodules.datamodule_base import get_pretrained_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pa.ipc.RecordBatchFileReader(\n",
    "    pa.memory_map(f\"dataset/normal_cap/cosmos_test.arrow\", \"r\")\n",
    ").read_all().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util, models\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "# from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Define the model. Either from scratch of by loading a pre-trained model\n",
    "model = SentenceTransformer('stsb-roberta-base-v2')\n",
    "\n",
    "#Define your train examples. You need more than just two examples...\n",
    "# train_examples = [\n",
    "#     InputExample(texts=['My first sentence', 'My second sentence'], label=0.8),\n",
    "#     InputExample(texts=['Another pair', 'Unrelated sentence'], label=0.3)]\n",
    "\n",
    "# #Define your train dataset, the dataloader and the train loss\n",
    "# train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "# train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# #Tune the model\n",
    "# model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/vilt2/lib/python3.7/site-packages/tqdm/std.py:702: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 1700/1700 [00:34<00:00, 49.33it/s]\n",
      "100%|██████████| 1700/1700 [00:26<00:00, 63.76it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['emp_1'] = df['caption_1'].progress_apply(lambda x: model.encode(x[0],convert_to_tensor=True))\n",
    "df['emp_2'] = df['caption_2'].progress_apply(lambda x: model.encode(x[0],convert_to_tensor=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [00:00<00:00, 5894.75it/s]\n"
     ]
    }
   ],
   "source": [
    "df['score'] = df.progress_apply(lambda x: util.cos_sim(x.emp_1, x.emp_2)[0][0], axis=1)\n",
    "df['label']= df['label'].apply(lambda x:x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7294117647058823 0.526 Actual     False  True \n",
      "Predicted              \n",
      "False        558    168\n",
      "True         292    682\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "max_at = 0\n",
    "confusion_matrix_max = []\n",
    "for i in np.arange(0.52, 0.55, 0.001):\n",
    "    df['predict'] = df['score'] < i\n",
    "    confusion_matrix = pd.crosstab(df['predict'], df['label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "    result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "    if result > max:\n",
    "        max = result\n",
    "        max_at = i\n",
    "        confusion_matrix_max = confusion_matrix\n",
    "print(max, max_at, confusion_matrix_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual     False  True \n",
      "Predicted              \n",
      "False        585    214\n",
      "True         265    636\n"
     ]
    }
   ],
   "source": [
    "# 0.5\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7182352941176471"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(585     + 636)/1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual     False  True \n",
      "Predicted              \n",
      "False        407    130\n",
      "True         443    720\n"
     ]
    }
   ],
   "source": [
    "# 0.6\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual     False  True \n",
      "Predicted              \n",
      "False        407    130\n",
      "True         443    720\n"
     ]
    }
   ],
   "source": [
    "# 0.6\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6164705882352941,\n",
       " 0.6464705882352941,\n",
       " 0.6629411764705883,\n",
       " 0.6294117647058823)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(632 + 416)/1700,(564+535) /1700,(407+720)/1700,(268+802)/1700\n",
    "#0.4 0.5 0.6 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PERSON at his announcement in GPE, GPE, on DATE. Mr. PERSON, the former secretary of housing and urban development, would be one of the youngest presidents if elected.]</td>\n",
       "      <td>[PERSON at his announcement in GPE, GPE, on DATE.]</td>\n",
       "      <td>tensor(0.5605, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Supporters of GPE's ruling ORG party come out on DATE to celebrate their candidate's victory in the disputed GPE presidential election]</td>\n",
       "      <td>[A person sits on a truck as supporters of the ruling ORG) celebrate the victory of their candidate in the Zanzibar Presidential election on the outskirts of GPE, on DATE.]</td>\n",
       "      <td>tensor(0.4889, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Men from the LOC tribe perform a traditional jumping ritual as they observe a rite of passage to mark the transition to cultural junior elder within the Masai-Mara national reserve.]</td>\n",
       "      <td>[And on DATE in GPE's Narok county, young PERSON men take part in initiation rites to become moran - the men who are traditionally the warrior class.]</td>\n",
       "      <td>tensor(0.4662, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[A man brushes the mouth of a sarcophagus.]</td>\n",
       "      <td>[CARDINAL statues of ancient deities and funerary masks were also discovered at the site, many of which still with their original colours and designs preserved]</td>\n",
       "      <td>tensor(0.1699, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[In GPE, tuk-tuks that used to transport tourists around the city are seen idle because of travel bans and border closures during the pandemic.]</td>\n",
       "      <td>[Tuk-tuk car parked in GPE because there are no tourists]</td>\n",
       "      <td>tensor(0.5748, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>[PERSON taking a photo]</td>\n",
       "      <td>[A child holds a camera next to a destroyed bus]</td>\n",
       "      <td>tensor(0.4245, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>[A man exercises on a street in GPE]</td>\n",
       "      <td>[A man jumps over a skipping rope in a street]</td>\n",
       "      <td>tensor(0.4664, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>[PERSON, left, and PERSON in \"WORK_OF_ART.\"]</td>\n",
       "      <td>[PERSON and PERSON]</td>\n",
       "      <td>tensor(0.5449, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>[Homeless people living on streets in GPE]</td>\n",
       "      <td>[ORG in GPE]</td>\n",
       "      <td>tensor(0.2635, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>[The castle's esplanade was a perfect spot for some off-piste skiing]</td>\n",
       "      <td>[Picture shows an ORG skier]</td>\n",
       "      <td>tensor(0.3602, device='cuda:0')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    caption_1  \\\n",
       "0                   [PERSON at his announcement in GPE, GPE, on DATE. Mr. PERSON, the former secretary of housing and urban development, would be one of the youngest presidents if elected.]   \n",
       "1                                                    [Supporters of GPE's ruling ORG party come out on DATE to celebrate their candidate's victory in the disputed GPE presidential election]   \n",
       "4     [Men from the LOC tribe perform a traditional jumping ritual as they observe a rite of passage to mark the transition to cultural junior elder within the Masai-Mara national reserve.]   \n",
       "9                                                                                                                                                 [A man brushes the mouth of a sarcophagus.]   \n",
       "11                                           [In GPE, tuk-tuks that used to transport tourists around the city are seen idle because of travel bans and border closures during the pandemic.]   \n",
       "...                                                                                                                                                                                       ...   \n",
       "1687                                                                                                                                                                  [PERSON taking a photo]   \n",
       "1691                                                                                                                                                     [A man exercises on a street in GPE]   \n",
       "1693                                                                                                                                             [PERSON, left, and PERSON in \"WORK_OF_ART.\"]   \n",
       "1697                                                                                                                                               [Homeless people living on streets in GPE]   \n",
       "1698                                                                                                                    [The castle's esplanade was a perfect spot for some off-piste skiing]   \n",
       "\n",
       "                                                                                                                                                                         caption_2  \\\n",
       "0                                                                                                                               [PERSON at his announcement in GPE, GPE, on DATE.]   \n",
       "1     [A person sits on a truck as supporters of the ruling ORG) celebrate the victory of their candidate in the Zanzibar Presidential election on the outskirts of GPE, on DATE.]   \n",
       "4                           [And on DATE in GPE's Narok county, young PERSON men take part in initiation rites to become moran - the men who are traditionally the warrior class.]   \n",
       "9                 [CARDINAL statues of ancient deities and funerary masks were also discovered at the site, many of which still with their original colours and designs preserved]   \n",
       "11                                                                                                                       [Tuk-tuk car parked in GPE because there are no tourists]   \n",
       "...                                                                                                                                                                            ...   \n",
       "1687                                                                                                                              [A child holds a camera next to a destroyed bus]   \n",
       "1691                                                                                                                                [A man jumps over a skipping rope in a street]   \n",
       "1693                                                                                                                                                           [PERSON and PERSON]   \n",
       "1697                                                                                                                                                                  [ORG in GPE]   \n",
       "1698                                                                                                                                                  [Picture shows an ORG skier]   \n",
       "\n",
       "                                score  \n",
       "0     tensor(0.5605, device='cuda:0')  \n",
       "1     tensor(0.4889, device='cuda:0')  \n",
       "4     tensor(0.4662, device='cuda:0')  \n",
       "9     tensor(0.1699, device='cuda:0')  \n",
       "11    tensor(0.5748, device='cuda:0')  \n",
       "...                               ...  \n",
       "1687  tensor(0.4245, device='cuda:0')  \n",
       "1691  tensor(0.4664, device='cuda:0')  \n",
       "1693  tensor(0.5449, device='cuda:0')  \n",
       "1697  tensor(0.2635, device='cuda:0')  \n",
       "1698  tensor(0.3602, device='cuda:0')  \n",
       "\n",
       "[443 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df.loc[(df['label']==False) & (df['predict']==True),['caption_1','caption_2','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1500]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1 = model.encode('PERSON and PERSON', convert_to_tensor=True)\n",
    "embeddings2 = model.encode('A man exercises on a street in GPE', convert_to_tensor=True)\n",
    "util.cos_sim(embeddings1, embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd6ac6d03954cf65a3aa8ce4cedda9aac0145a018ad67eca07aa9c761ef41ce4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('vilt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
