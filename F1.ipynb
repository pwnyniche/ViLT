{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "from PIL import Image\n",
    "import pyarrow as pa\n",
    "from vilt.config import ex\n",
    "from vilt.modules import ViLTransformerSS\n",
    "\n",
    "# from vilt.modules.objectives import cost_matrix_cosine, ipot\n",
    "from vilt.transforms import pixelbert_transform\n",
    "from vilt.datamodules.datamodule_base import get_pretrained_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pa.ipc.RecordBatchFileReader(\n",
    "    pa.memory_map(f\"dataset_50/cosmos_test.arrow\", \"r\")\n",
    ").read_all().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_config = {'exp_name': 'vilt', 'seed': 0, 'datasets': ['coco', 'vg', 'sbu', 'gcc'], 'loss_names': {'itm': 1, 'mlm': 1, 'mpp': 0, 'vqa': 0, 'nlvr2': 0, 'irtr': 0, 'cosmos': 0}, 'batch_size': 4096, 'train_transform_keys': ['pixelbert'], 'val_transform_keys': ['pixelbert'], 'image_size': 384, 'max_image_len': -1, 'patch_size': 32, 'draw_false_image': 1, 'image_only': False, 'vqav2_label_size': 3129, 'max_text_len': 40, 'tokenizer': 'bert-base-uncased', 'vocab_size': 30522, 'whole_word_masking': False, 'mlm_prob': 0.15, 'draw_false_text': 0, 'vit': 'vit_base_patch32_384', 'hidden_size': 768, 'num_heads': 12, 'num_layers': 12, 'mlp_ratio': 4, 'drop_rate': 0.1, 'optim_type': 'adamw', 'learning_rate': 0.0001, 'weight_decay': 0.01, 'decay_power': 1, 'max_epoch': 100, 'max_steps': 25000, 'warmup_steps': 2500, 'end_lr': 0, 'lr_mult': 1, 'get_recall_metric': False, 'resume_from': None, 'fast_dev_run': False, 'val_check_interval': 1.0, 'test_only': False, 'data_root': '', 'log_dir': 'result', 'per_gpu_batchsize': 0, 'num_gpus': 1, 'num_nodes': 1, \n",
    "    'load_path': 'result/data_neg_seed0_from_vilt_200k_mlm_itm/version_1/checkpoints/epoch=0-step=8045.ckpt', 'num_workers': 8, 'precision': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_names = {\n",
    "        \"itm\": 0,\n",
    "        \"mlm\": 0,\n",
    "        \"mpp\": 0,\n",
    "        \"vqa\": 0,\n",
    "        \"imgcls\": 0,\n",
    "        \"nlvr2\": 0,\n",
    "        \"irtr\": 0,\n",
    "        \"arc\": 0,\n",
    "        \"cosmos\":1\n",
    "    }\n",
    "tokenizer = get_pretrained_tokenizer(_config[\"tokenizer\"])\n",
    "\n",
    "_config.update(\n",
    "    {\n",
    "        \"loss_names\": loss_names,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViLTransformerSS(_config)\n",
    "model.setup(\"test\")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if _config[\"num_gpus\"] > 0 else \"cpu\"\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "bert = SentenceTransformer('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def infer(image,text,text2):\n",
    "    img = pixelbert_transform(size=384)(image)\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "    batch = {\"text\": [text], \"image\": [img], \"text2\": [text2]}\n",
    "    with torch.no_grad():\n",
    "        encoded = tokenizer(batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=40,\n",
    "        return_special_tokens_mask=True)\n",
    "        batch[\"text_ids\"] = torch.tensor(encoded[\"input_ids\"]).to(device)\n",
    "        batch[\"text_labels\"] = torch.tensor(encoded[\"input_ids\"]).to(device)\n",
    "        batch[\"text_masks\"] = torch.tensor(encoded[\"attention_mask\"]).to(device)\n",
    "\n",
    "        encoded = tokenizer(batch[\"text2\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=40,\n",
    "        return_special_tokens_mask=True)\n",
    "        batch[\"text2_ids\"] = torch.tensor(encoded[\"input_ids\"]).to(device)\n",
    "        batch[\"text2_labels\"] = torch.tensor(encoded[\"input_ids\"]).to(device)\n",
    "        batch[\"text2_masks\"] = torch.tensor(encoded[\"attention_mask\"]).to(device)\n",
    "\n",
    "        infer1 = model.infer(batch, text_token_type_idx=1)\n",
    "        infer2 = model.infer(batch, text_token_type_idx=2)\n",
    "        cls_feats = torch.cat([infer1[\"cls_feats\"], infer2[\"cls_feats\"]], dim=-1)\n",
    "\n",
    "        cosmos_logits = model.nlvr2_classifier(cls_feats)\n",
    "    # encoded = encoded[\"input_ids\"][0][1:-1]\n",
    "    # inferred_token = [tokenizer.decode(encoded)]\n",
    "    # return infer1,inferred_token\n",
    "    sm = nn.Softmax(dim=-1)\n",
    "    return  sm(cosmos_logits).tolist()[0][1]\n",
    "    # return cosmos_logits.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_image(img_byte):\n",
    "    image_bytes = io.BytesIO(img_byte)\n",
    "    image_bytes.seek(0)\n",
    "    return Image.open(image_bytes).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp_1'] = df['caption_1'].apply(lambda x: bert.encode(x[0],convert_to_tensor=True))\n",
    "df['emp_2'] = df['caption_2'].apply(lambda x: bert.encode(x[0],convert_to_tensor=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df.apply(lambda x: util.cos_sim(x.emp_1, x.emp_2)[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626351356506348"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(get_raw_image(r['image']), r['caption_1'][0], r['caption_2'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [01:13<00:00, 23.25it/s]\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame({},columns=['ooc_score','label','cap1','cap2'])\n",
    "for i in tqdm(np.arange(len(df))):\n",
    "    r = df.iloc[i]\n",
    "    ans = r['label']\n",
    "    # if r['nli']=='entail':\n",
    "    #     result.loc[len(result)] = [0, ans,r['caption_1'][0],r['caption_2'][0]]\n",
    "    #     continue\n",
    "    # if r['score']>0.85:\n",
    "    #     result.loc[len(result)] = [0, ans,r['caption_1'][0],r['caption_2'][0]]\n",
    "    #     continue\n",
    "    pred = infer(get_raw_image(r['image']), r['caption_1'][0], r['caption_2'][0])\n",
    "    # s = util.cos_sim(model2.encode(r['caption_1'][0]),(model2.encode(r['caption_2'][0])))\n",
    "    # pred = pred == True\n",
    "    \n",
    "    result.loc[len(result)] = [pred, ans,r['caption_1'][0],r['caption_2'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1700.000000\n",
       "mean        0.476784\n",
       "std         0.358492\n",
       "min         0.005042\n",
       "25%         0.110517\n",
       "50%         0.437559\n",
       "75%         0.834824\n",
       "max         0.999769\n",
       "Name: ooc_score, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['ooc_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['predict1']=result['ooc_score']>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['ooc_score'].to_csv('vilt.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual     False  True \n",
      "Predicted              \n",
      "False        617    292\n",
      "True         233    558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6911764705882353"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(result['predict1'], result['label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print (confusion_matrix)\n",
    "(confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6911764705882353"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6911764705882353"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(617+558)/1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual     False  True \n",
      "Predicted              \n",
      "False        812    504\n",
      "True          38    346\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(result['predict'], result['label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual     False  True \n",
      "Predicted              \n",
      "False        651    409\n",
      "True         199    441\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(result['predict'], result['label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6423529411764706"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(651+ 441)/1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6811764705882353"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(812 + 346) / (1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df['score'].apply(lambda x:x.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict1</th>\n",
       "      <th>label</th>\n",
       "      <th>cap1</th>\n",
       "      <th>cap2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>PERSON at his announcement in GPE, GPE, on DAT...</td>\n",
       "      <td>PERSON at his announcement in GPE, GPE, on DATE.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Supporters of GPE's ruling ORG party come out ...</td>\n",
       "      <td>A person sits on a truck as supporters of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>CARDINAL dead people turned up on the state’s ...</td>\n",
       "      <td>These social media posts did not link to a rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Actor, musician, director and devoted follower...</td>\n",
       "      <td>A shocking report about the former child actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Men from the LOC tribe perform a traditional j...</td>\n",
       "      <td>And on DATE in GPE's Narok county, young PERSO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>President PERSON trademarked the name 'WORK_OF...</td>\n",
       "      <td>There was no truth that PERSON family MONEY wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A photograph shows a soldier carrying a donkey...</td>\n",
       "      <td>Coronavirus meme featuring “EVENT donkey” is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Homeless people living on streets in GPE</td>\n",
       "      <td>ORG in GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The castle's esplanade was a perfect spot for ...</td>\n",
       "      <td>Picture shows an ORG skier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>We are confident that our reporting will stand...</td>\n",
       "      <td>ORG Editor-in-Chief PERSON poses for a picture...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predict1  label                                               cap1  \\\n",
       "0           0  False  PERSON at his announcement in GPE, GPE, on DAT...   \n",
       "1           0  False  Supporters of GPE's ruling ORG party come out ...   \n",
       "2        True   True  CARDINAL dead people turned up on the state’s ...   \n",
       "3        True   True  Actor, musician, director and devoted follower...   \n",
       "4       False  False  Men from the LOC tribe perform a traditional j...   \n",
       "...       ...    ...                                                ...   \n",
       "1695     True   True  President PERSON trademarked the name 'WORK_OF...   \n",
       "1696     True   True  A photograph shows a soldier carrying a donkey...   \n",
       "1697     True  False           Homeless people living on streets in GPE   \n",
       "1698    False  False  The castle's esplanade was a perfect spot for ...   \n",
       "1699     True   True  We are confident that our reporting will stand...   \n",
       "\n",
       "                                                   cap2  \n",
       "0      PERSON at his announcement in GPE, GPE, on DATE.  \n",
       "1     A person sits on a truck as supporters of the ...  \n",
       "2     These social media posts did not link to a rec...  \n",
       "3     A shocking report about the former child actor...  \n",
       "4     And on DATE in GPE's Narok county, young PERSO...  \n",
       "...                                                 ...  \n",
       "1695  There was no truth that PERSON family MONEY wi...  \n",
       "1696  Coronavirus meme featuring “EVENT donkey” is n...  \n",
       "1697                                         ORG in GPE  \n",
       "1698                         Picture shows an ORG skier  \n",
       "1699  ORG Editor-in-Chief PERSON poses for a picture...  \n",
       "\n",
       "[1700 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[(df['nli']=='contradiction')]['score'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    63\n",
       "True      7\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['score']>0.9)]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[A man brushes the mouth of a sarcophagus.]</td>\n",
       "      <td>[CARDINAL statues of ancient deities and funerary masks were also discovered at the site, many of which still with their original colours and designs preserved]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[A tribute to Captain Sir PERSON lights up ORG, GPE. The DATE, who raised almost ORGm for ORG charities by walking laps of his garden, died with coronavirus.]</td>\n",
       "      <td>[A woman plays the violin in ORG during a tribute to Captain Sir PERSON on 2 DATE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[The PERSON and ORG, ORG, by PERSON, from the GPE]</td>\n",
       "      <td>[A sacred cow in a street in GPE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[Lex Scott Davis and PERSON in \"WORK_OF_ART.\"]</td>\n",
       "      <td>[PERSON (right) plays a suave drug dealer named Priest and PERSON is GPE in GPE, Director X’s blinged-out redo of the DATE blaxploitation classic.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[NORP paramilitary troops in GPE in GPE DATE. PERCENT of the army's equipment is so old that it is officially considered \"vintage.\"]</td>\n",
       "      <td>[LOC braces for worst as shelling, gunbattles escalate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>[Mr. PERSON won the fiercely contested race by CARDINAL votes, out of CARDINAL.]</td>\n",
       "      <td>[PERSON, the NORP candidate for ORG, is accompanied by his wife, PERSON, at an LOC gathering of his supporters in GPE, GPE, on DATE.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>[Heavy snowfall had be be cleared on FAC during one of the DATE in the early 1900s]</td>\n",
       "      <td>[CARDINAL - Duke Street, Barrow-in-Furness DATE-CARDINAL ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>[A photographer's self portrait with her mother is one of many works featured at ORG ORDINAL DATE NORP Foto Festival.]</td>\n",
       "      <td>[CARDINAL women embrace, wearing face masks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>[PERSON taking a photo]</td>\n",
       "      <td>[A child holds a camera next to a destroyed bus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>[Supporters of PERSON, the newly declared winner, in GPE on DATE.]</td>\n",
       "      <td>[Residents celebrate in GPE, GPE, on DATE after the election results were announced.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                           caption_1  \\\n",
       "9                                                                                                                        [A man brushes the mouth of a sarcophagus.]   \n",
       "21    [A tribute to Captain Sir PERSON lights up ORG, GPE. The DATE, who raised almost ORGm for ORG charities by walking laps of his garden, died with coronavirus.]   \n",
       "48                                                                                                                [The PERSON and ORG, ORG, by PERSON, from the GPE]   \n",
       "52                                                                                                                    [Lex Scott Davis and PERSON in \"WORK_OF_ART.\"]   \n",
       "64                              [NORP paramilitary troops in GPE in GPE DATE. PERCENT of the army's equipment is so old that it is officially considered \"vintage.\"]   \n",
       "...                                                                                                                                                              ...   \n",
       "1654                                                                                [Mr. PERSON won the fiercely contested race by CARDINAL votes, out of CARDINAL.]   \n",
       "1667                                                                             [Heavy snowfall had be be cleared on FAC during one of the DATE in the early 1900s]   \n",
       "1678                                          [A photographer's self portrait with her mother is one of many works featured at ORG ORDINAL DATE NORP Foto Festival.]   \n",
       "1687                                                                                                                                         [PERSON taking a photo]   \n",
       "1689                                                                                              [Supporters of PERSON, the newly declared winner, in GPE on DATE.]   \n",
       "\n",
       "                                                                                                                                                             caption_2  \n",
       "9     [CARDINAL statues of ancient deities and funerary masks were also discovered at the site, many of which still with their original colours and designs preserved]  \n",
       "21                                                                                  [A woman plays the violin in ORG during a tribute to Captain Sir PERSON on 2 DATE]  \n",
       "48                                                                                                                                   [A sacred cow in a street in GPE]  \n",
       "52                 [PERSON (right) plays a suave drug dealer named Priest and PERSON is GPE in GPE, Director X’s blinged-out redo of the DATE blaxploitation classic.]  \n",
       "64                                                                                                             [LOC braces for worst as shelling, gunbattles escalate]  \n",
       "...                                                                                                                                                                ...  \n",
       "1654                             [PERSON, the NORP candidate for ORG, is accompanied by his wife, PERSON, at an LOC gathering of his supporters in GPE, GPE, on DATE.]  \n",
       "1667                                                                                                     [CARDINAL - Duke Street, Barrow-in-Furness DATE-CARDINAL ORG]  \n",
       "1678                                                                                                                      [CARDINAL women embrace, wearing face masks]  \n",
       "1687                                                                                                                  [A child holds a camera next to a destroyed bus]  \n",
       "1689                                                                             [Residents celebrate in GPE, GPE, on DATE after the election results were announced.]  \n",
       "\n",
       "[159 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong = df[(result['predict'] != result ['label']) & (result['predict']==True)]\n",
    "wrong[['caption_1','caption_2']]\n",
    "# correct_true['caption_1'].iloc[0],correct_true['caption_2'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_raw_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_186881/3489057191.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_raw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1687\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_raw_image' is not defined"
     ]
    }
   ],
   "source": [
    "get_raw_image(df['image'].iloc[1687])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9a86a7ed262735ebe154e2af3d12815b689f8138287f40a62edb0c9d1ca95e9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('vilt2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
